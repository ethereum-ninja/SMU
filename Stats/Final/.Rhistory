knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(sqldf)
library(dplyr)
library(VGAM)
library(caret)
library(nnet)
test_train_split = 0.4
df = 93
alpha = .05
critical_t = function(alpha, df, two_sided=TRUE){
if(two_sided){
t = qt(1-alpha/2, df = df)
}
else{
t = qt(1-alpha, df = df)
}
return(t)
}
p_val = function(t, df, sides=2){
p = sides * pt(t, df, lower.tail = F)
return(p)
}
loadData <-function(filename){
data = read.csv(filename, stringsAsFactors=FALSE)
return(data)
}
#helper functions
generate_interaction_string <- function(columns){
#f = paste(columns, ':')
f = c()
for(x in columns)
for(y in columns)
{
if(x != y)
if(!is.element(glue::glue('{y}:{x}'),f))
f = append(f, glue::glue('{x}:{y}'))
}
return(f)
}
build_model_string <- function(target, columns, interactions=c()){
model = c(columns, interactions)
target_string = glue::glue("{target} ~ ")
model_string = paste(model, collapse="+")
f = target_string + model_string
return(f)
}
run_linear_model <- function(data, target, columns, interactions=c()){
model = c(columns, interactions)
f = build_model_string(target, columns, interactions)
sample = select(data, columns, target)
#Train Test Split
seed = 1234
sample_size = floor(test_train_split*nrow(sample))
set.seed(seed)
train_set = sample(seq_len(nrow(sample)), size=sample_size)
train = sample[train_set,]
test = sample[-train_set,]
#Build the model
linear_model <-vglm(as.formula(f),family = "multinomial",data=train)
#Summarize the model
#print(summary(linear_model))
#Run Predictions
x<-select(test, -target)
y<-select(test, target)
probability<-predict(linear_model,x,type="response")
test$pred_log_reg<-apply(probability,1,which.max)
test$pred_log_reg[which(test$pred_log_reg=="1")]<-levels(test[,target])[1]
test$pred_log_reg[which(test$pred_log_reg=="2")]<-levels(test[,target])[2]
#Accuracy of the model
mtab<-table(test$pred_log_reg,test[,target])
confusion = confusionMatrix(mtab)
return(list(linear_model, f, mtab, confusion))
}
run_nn_model <- function(data, target, columns, interactions=c()){
model = c(columns, interactions)
f = build_model_string(target, columns, interactions)
sample = select(data, columns, target)
#Train Test Split
seed = 1234
sample_size = floor(test_train_split*nrow(sample))
set.seed(seed)
train_set = sample(seq_len(nrow(sample)), size=sample_size)
train = sample[train_set,]
test = sample[-train_set,]
#Build the model
neural_model <-nnet(as.formula(f),data=train,size = 4,decay = 0.0001,maxit = 500)
#Summarize the model
#print(summary(neural_model))
#Run Predictions
x<-select(test, -target)
y<-select(test, target)
#Predict using the model
test$pred_nnet<-predict(neural_model,x,type='class')
#str(f)
#Accuracy of the model
mtab<-table(test$pred_nnet,test[,target])
#print(summary(mtab))
confusion = confusionMatrix(mtab)
return(list(neural_model, f, mtab, confusion))
}
#helper function for extracting col names
#TODO: add cols that are factors but also ints
factor_columns <- function(dataFrame){
return(colnames(dataFrame[,sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
non_factor_columns <- function(dataFrame){
return(colnames(dataFrame[, !sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
glucose_data = loadData('GlucoseGeneStudy_mod.csv')
glucose_data$Glucose = as.double(glucose_data$Glucose)
glucose_data$Gender = factor(glucose_data$Gender)
glucose_data$Race = factor(glucose_data$Race)
simple_model = lm(data=glucose_data, formula = Glucose ~ Gender+X10)
summary(simple_model)
prediction_confidence = predict(simple_model, newdata = data.frame(Gender="M",X10=17), interval = c("confidence"), type = c("response"), level =0.99)
prediction_predict = predict(simple_model, newdata = data.frame(Gender="M",X10=17), interval = c("predict"), type = c("response"), level =0.99)
experiment_data = loadData('GlucoseGeneStudy_mod.csv')
#let's remove categorical variables since we only seek to look for gene relationships
experiment_data[, 'Gender'] = c(NULL)
experiment_data[, 'Race'] = c(NULL)
f = build_model_string(target = 'Glucose', columns=colnames(experiment_data[,2:41]))
experiment_interactions = c() #assumue none for now
full_model = lm(data=experiment_data, formula=as.formula(f))
summary(full_model)
test_data = loadData('GlucoseGeneStudy_mod.csv')
simpler_model = lm(data=test_data, formula = Glucose ~ X10+log(X4)+X16+X17+X28+X29)
summary(simpler_model)
