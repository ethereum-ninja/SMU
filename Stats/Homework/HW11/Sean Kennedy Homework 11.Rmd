---
title: "Statistical Foundations for Data Science - HW11 - Sean Kennedy"
author: "Sean Kennedy"
date: "8/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sqldf)
library(tidyverse)
library(investr)
```

```{r, echo=FALSE}


critical_t = function(alpha, df, two_sided=TRUE){
  if(two_sided){
    t = qt(1-alpha/2, df = df)
  }
  else{
     t = qt(1-alpha, df = df)
  }
  return(t)  
}

p_val = function(t, df, sides=2){
  p = sides * pt(t, df, lower.tail = F)
  return(p)
}

#assumes 99% CL

```

## Load Data

```{r}
metabolic_data = read.csv('Metabolism Data Prob 26.csv')
metabolic_data$Mass_mod = metabolic_data$Mass^(0.75) 
summary(metabolic_data)
```


## Question 1: Metabolic Rate vs Mass

  Assess relationship between mass metabolic rate:
  
  {meta|mass}: meta = B0 + B1(mass)
  
  or
  
  {meta|mass_.75}: meta = B0 + B1(mass)

```{r}
ggplot(data=metabolic_data) + 
  geom_point(aes(x=Mass, y=Metab), color='Red') +
  geom_point(aes(x=Mass_mod, y=Metab), color='Blue') 
  
```

## Data does appear to be linear for both inputs (mass and mass^0.75) 
    
    Trend is stronger for X^3/4

```{r}

mass_model = lm(data=metabolic_data, formula = Metab ~ Mass_mod)
summary(mass_model)
```
    



## Plot CL

```{r}
bird_plot = ggplot(metabolic_data, aes(x=Mass_mod, y=Metab)) +
  geom_point(color='Blue', size = 2) +
  geom_smooth(method = lm, se=TRUE, level=0.99, color='Red')

predictions_cl = predict(mass_model, newdata = data.frame(Mass_mod = sort(metabolic_data$Mass_mod)), interval = c('predict'), type=c('response'), level=0.99)

regress_cl = predict(mass_model, newdata = data.frame(Mass_mod = sort(metabolic_data$Mass_mod)), interval = c('confidence'), type=c('response'), level=0.99)

bird_plot +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(metabolic_data$Mass_mod), y=upr), color='Green') +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(metabolic_data$Mass_mod), y=lwr), color='Green') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(metabolic_data$Mass_mod), y=upr), color='Blue') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(metabolic_data$Mass_mod), y=lwr), color='Blue')
```
```{r}
plot(mass_model)
```

## Try log transform


```{r}
log_data = metabolic_data
log_data$Meta_log = log(log_data$Metab)
log_data$Mass_mod_log = log(log_data$Mass_mod)
ggplot(data=log_data) + 
  geom_point(aes(x=Mass_mod_log, y=Meta_log), color='Red') +
  geom_point(aes(x=Mass_mod_log, y=Meta_log), color='Blue') 

log_model = lm(data=log_data, formula = Meta_log ~ Mass_mod_log)

bird_plot = ggplot(log_data, aes(x=Mass_mod_log, y=Meta_log)) +
  geom_point(color='Blue', size = 2) +
  geom_smooth(method = lm, se=TRUE, level=0.99, color='Red')

predictions_cl = predict(log_model, newdata = data.frame(Mass_mod_log = sort(log_data$Mass_mod_log)), interval = c('predict'), type=c('response'), level=0.99)

regress_cl = predict(log_model, newdata = data.frame(Mass_mod_log = sort(log_data$Mass_mod_log)), interval = c('confidence'), type=c('response'), level=0.99)

bird_plot +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Mass_mod_log), y=upr), color='Green') +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Mass_mod_log), y=lwr), color='Green') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Mass_mod_log), y=upr), color='Blue') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Mass_mod_log), y=lwr), color='Blue')

m<-mean(log_model$residuals)
std<-sqrt(var(log_model$residuals))
hist(log_model$residuals, breaks=20, prob=TRUE, 
     xlab="x-variable", ylim=c(0, 2), 
     main="normal curve over histogram") 
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
plot(log_model)
```

## Much Better to use log/log

   Meets assumptions for normality, linearity, equal variance and independence 
   
   Outliers are not an issue according to Cookd measures


```{r}
summary(log_model)
confint(log_model)

```
## Regression Equation

{log(Meta):log(Mass)}: B0 + B1log(Mass) = 5.64 + 0.98log(Mass)

## Interpretation

  A doubling of the mass corresponds to a 98% increase in the expected median of Metabolic activity
  
  A 95% confidence interval for this effect is [94%, 102%]
  
  96% of the variability is explained by the model
  
  
## Question 2

```{r}
autism_data = read.csv('Autism Data Prob 29.csv')
summary(autism_data)
autism_model = lm(data=autism_data, formula = Prevalence ~ Year)
summary(autism_model)
plot(autism_model)

ggplot(data=autism_data) + 
  geom_point(aes(x=Year, y=Prevalence), color='Red') +
  geom_point(aes(x=Year, y=Prevalence), color='Blue') 

autism_model = lm(data=autism_data, formula = Prevalence ~ Year)

bird_plot = ggplot(autism_data, aes(x=Year, y=Prevalence)) +
  geom_point(color='Blue', size = 2) +
  geom_smooth(method = lm, se=TRUE, level=0.99, color='Red')

predictions_cl = predict(autism_model, newdata = data.frame(Year = sort(autism_data$Year)), interval = c('predict'), type=c('response'), level=0.99)

regress_cl = predict(autism_model, newdata = data.frame(Year = sort(autism_data$Year)), interval = c('confidence'), type=c('response'), level=0.99)

bird_plot +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(autism_data$Year), y=upr), color='Green') +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(autism_data$Year), y=lwr), color='Green') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(autism_data$Year), y=upr), color='Blue') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(autism_data$Year), y=lwr), color='Blue')

m<-mean(autism_model$residuals)
std<-sqrt(var(autism_model$residuals))
hist(autism_model$residuals, breaks=20, prob=TRUE, 
     xlab="x-variable", ylim=c(0, 2), 
     main="normal curve over histogram")
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
plot(autism_model)

```

## This model is trash - transformers GO!

    Log Linear
    
```{r}
log_data = autism_data
log_data$Prevalence_log = log(log_data$Prevalence)

autism_model = lm(data=log_data, formula = Prevalence_log ~ Year)
summary(autism_model)
plot(autism_model)

ggplot(data=log_data) + 
  geom_point(aes(x=Year, y=Prevalence_log), color='Red') +
  geom_point(aes(x=Year, y=Prevalence_log), color='Blue') 

autism_model = lm(data=log_data, formula = Prevalence_log ~ Year)

bird_plot = ggplot(log_data, aes(x=Year, y=Prevalence_log)) +
  geom_point(color='Blue', size = 2) +
  geom_smooth(method = lm, se=TRUE, level=0.99, color='Red')

predictions_cl = predict(autism_model, newdata = data.frame(Year = sort(log_data$Year)), interval = c('predict'), type=c('response'), level=0.99)

regress_cl = predict(autism_model, newdata = data.frame(Year = sort(log_data$Year)), interval = c('confidence'), type=c('response'), level=0.99)

bird_plot +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Year), y=upr), color='Green') +
  geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Year), y=lwr), color='Green') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Year), y=upr), color='Blue') +
  geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Year), y=lwr), color='Blue')

m<-mean(autism_model$residuals)
std<-sqrt(var(autism_model$residuals))
hist(autism_model$residuals, freq = TRUE, breaks=20) 
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
plot(autism_model)

```



# Much better!

  Still very hard to run a regression for such a small sample - but that's the assigment... sooooo
  
  Meets assumptions for normality, linearity, equal variance and independence 
   
  Outliers are not an issue according to Cookd measures

## Regression Equation

{log(Prevalence):Year)}: B0 + B1Year = -408 + 0.020Year

## Interpretation

  A multiplicative effect of year on prevalance of 23% is predicted by the model
  
  A 95% confidence interval for this effect is [22%, 24%]
  
  99% of the variability is explained by the model
  
  (note that there is no reason to suspect that year should be a part of this model, model is nonsense)
