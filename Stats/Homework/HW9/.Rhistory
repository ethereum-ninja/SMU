geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Year), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Year), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Year), y=lwr), color='Blue')
m<-mean(autism_model$residuals)
std<-sqrt(var(autism_model$residuals))
hist(autism_model$residuals, breaks=20)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
plot(autism_model)
log_data = autism_data
log_data$Prevalence_log = log(log_data$Prevalence)
autism_model = lm(data=log_data, formula = Prevalence_log ~ Year)
summary(autism_model)
plot(autism_model)
ggplot(data=log_data) +
geom_point(aes(x=Year, y=Prevalence_log), color='Red') +
geom_point(aes(x=Year, y=Prevalence_log), color='Blue')
autism_model = lm(data=log_data, formula = Prevalence_log ~ Year)
bird_plot = ggplot(log_data, aes(x=Year, y=Prevalence_log)) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=0.99, color='Red')
predictions_cl = predict(autism_model, newdata = data.frame(Year = sort(log_data$Year)), interval = c('predict'), type=c('response'), level=0.99)
regress_cl = predict(autism_model, newdata = data.frame(Year = sort(log_data$Year)), interval = c('confidence'), type=c('response'), level=0.99)
bird_plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Year), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(log_data$Year), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Year), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(log_data$Year), y=lwr), color='Blue')
m<-mean(autism_model$residuals)
std<-sqrt(var(autism_model$residuals))
hist(autism_model$residuals, freq = TRUE, breaks=20)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
plot(autism_model)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sqldf)
library(tidyquant)
data = read.csv('Brain.csv')
View(data)
b_data = read.csv('Brain.csv')
pairs(~ Brain + Body + Gestation + Litter, data=b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
pairs(~ Brain_log + Body_log + Gestation_log + Litter, data=b_data)
View(b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter_Log, data=b_data)
b_data$Litter_log = log(b_data$Litter)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter_Log, data=b_data)
View(b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter_Log, data=b_data)
View(b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter, data=b_data)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sqldf)
library(tidyquant)
b_data = read.csv('Brain.csv')
pairs(~ Brain + Body + Gestation + Litter, data=b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter, data=b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter_log, data=b_data)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter_log, data=b_data)
log_model = lm(data=b_data, formula = Brain_log ~ Body_log + Gestation_log + Litter_log)
b_data$Brain_log = log(b_data$Brain)
b_data$Body_log = log(b_data$Body)
b_data$Gestation_log = log(b_data$Gestation)
b_data$Litter_log = log(b_data$Litter)
pairs(~ Brain_log + Body_log + Gestation_log + Litter_log, data=b_data)
log_model = lm(data=b_data, formula = Brain_log ~ Body_log + Gestation_log + Litter_log)
summary(log_model)
plot(log_model)
df = 93
alpha = .05
critical_t = function(alpha, df, two_sided=TRUE){
if(two_sided){
t = qt(1-alpha/2, df = df)
}
else{
t = qt(1-alpha, df = df)
}
return(t)
}
p_val = function(t, df, sides=2){
p = sides * pt(t, df, lower.tail = F)
return(p)
}
loadData <-function(filename){
data = read.csv(filename, stringsAsFactors=FALSE)
return(data)
}
#helper functions
generate_interaction_string <- function(columns){
#f = paste(columns, ':')
f = c()
for(x in columns)
for(y in columns)
{
if(x != y)
if(!is.element(glue::glue('{y}:{x}'),f))
f = append(f, glue::glue('{x}:{y}'))
}
return(f)
}
build_model_string <- function(target, columns, interactions=c()){
model = c(columns, interactions)
target_string = glue::glue("{target} ~ ")
model_string = paste(model, collapse="+")
f = target_string + model_string
return(f)
}
run_linear_model <- function(data, target, columns, interactions=c()){
model = c(columns, interactions)
f = build_model_string(target, columns, interactions)
sample = select(data, columns, target)
#Train Test Split
seed = 1234
sample_size = floor(test_train_split*nrow(sample))
set.seed(seed)
train_set = sample(seq_len(nrow(sample)), size=sample_size)
train = sample[train_set,]
test = sample[-train_set,]
#Build the model
linear_model <-vglm(as.formula(f),family = "multinomial",data=train)
#Summarize the model
#print(summary(linear_model))
#Run Predictions
x<-select(test, -target)
y<-select(test, target)
probability<-predict(linear_model,x,type="response")
test$pred_log_reg<-apply(probability,1,which.max)
test$pred_log_reg[which(test$pred_log_reg=="1")]<-levels(test[,target])[1]
test$pred_log_reg[which(test$pred_log_reg=="2")]<-levels(test[,target])[2]
#Accuracy of the model
mtab<-table(test$pred_log_reg,test[,target])
confusion = confusionMatrix(mtab)
return(list(linear_model, f, mtab, confusion))
}
run_nn_model <- function(data, target, columns, interactions=c()){
model = c(columns, interactions)
f = build_model_string(target, columns, interactions)
sample = select(data, columns, target)
#Train Test Split
seed = 1234
sample_size = floor(test_train_split*nrow(sample))
set.seed(seed)
train_set = sample(seq_len(nrow(sample)), size=sample_size)
train = sample[train_set,]
test = sample[-train_set,]
#Build the model
neural_model <-nnet(as.formula(f),data=train,size = 4,decay = 0.0001,maxit = 500)
#Summarize the model
#print(summary(neural_model))
#Run Predictions
x<-select(test, -target)
y<-select(test, target)
#Predict using the model
test$pred_nnet<-predict(neural_model,x,type='class')
#str(f)
#Accuracy of the model
mtab<-table(test$pred_nnet,test[,target])
#print(summary(mtab))
confusion = confusionMatrix(mtab)
return(list(neural_model, f, mtab, confusion))
}
#helper function for extracting col names
#TODO: add cols that are factors but also ints
factor_columns <- function(dataFrame){
return(colnames(dataFrame[,sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
non_factor_columns <- function(dataFrame){
return(colnames(dataFrame[, !sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
glucose_data = read.csv('GlucoseGeneStudy.csv') # loadData('GlucoseGeneStudy.csv')
glucose_data =  loadData('GlucoseGeneStudy.csv')
glucose_data$Glucose = as.double(glucose_data$Glucose)
glucose_data$Gender = factor(glucose_data$Gender)
glucose_data$Race = factor(glucose_data$Race)
simple_model = lm(data=glucose_data, formula = Glucose ~ Gender+X10)
summary(simple_model)
prediction_confidence = predict(simple_model, newdata = data.frame(Gender="M",X10=17), interval = c("confidence"), type = c("response"), level =0.99)
prediction_predict = predict(simple_model, newdata = data.frame(Gender="M",X10=17), interval = c("predict"), type = c("response"), level =0.99)
experiment_data = loadData('GlucoseGeneStudy_mod.csv')
#let's remove categorical variables since we only seek to look for gene relationships
experiment_data[, 'Gender'] = c(NULL)
experiment_data[, 'Race'] = c(NULL)
f = build_model_string(target = 'Glucose', columns=colnames(experiment_data[,2:41]))
experiment_interactions = c() #assumue none for now
full_model = lm(data=experiment_data, formula=as.formula(f))
summary(full_model)
test_data = loadData('GlucoseGeneStudy_mod.csv')
simpler_model = lm(data=test_data, formula = Glucose ~ X10+log(X4)+X16+X17+X28+X29)
summary(simpler_model)
experiment_data = loadData('GlucoseGeneStudy_mod.csv')
#let's remove categorical variables since we only seek to look for gene relationships
experiment_data[, 'Gender'] = c(NULL)
experiment_data[, 'Race'] = c(NULL)
f = build_model_string(target = 'Glucose', columns=colnames(experiment_data[,2:41]))
experiment_interactions = c() #assumue none for now
full_model = lm(data=experiment_data, formula=as.formula(f))
summary(full_model)
test_data = loadData('GlucoseGeneStudy_mod.csv')
simpler_model = lm(data=test_data, formula = Glucose ~ X10+log(X4)+X16+X17+X28+X29)
summary(simpler_model)
confint(simpler_model)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(sqldf)
library(dplyr)
library(VGAM)
library(caret)
library(nnet)
test_train_split = 0.4
df = 93
alpha = .05
critical_t = function(alpha, df, two_sided=TRUE){
if(two_sided){
t = qt(1-alpha/2, df = df)
}
else{
t = qt(1-alpha, df = df)
}
return(t)
}
p_val = function(t, df, sides=2){
p = sides * pt(t, df, lower.tail = F)
return(p)
}
loadData <-function(filename){
data = read.csv(filename, stringsAsFactors=FALSE)
return(data)
}
#helper functions
generate_interaction_string <- function(columns){
#f = paste(columns, ':')
f = c()
for(x in columns)
for(y in columns)
{
if(x != y)
if(!is.element(glue::glue('{y}:{x}'),f))
f = append(f, glue::glue('{x}:{y}'))
}
return(f)
}
build_model_string <- function(target, columns, interactions=c()){
model = c(columns, interactions)
target_string = glue::glue("{target} ~ ")
model_string = paste(model, collapse="+")
f = target_string + model_string
return(f)
}
run_linear_model <- function(data, target, columns, interactions=c()){
model = c(columns, interactions)
f = build_model_string(target, columns, interactions)
sample = select(data, columns, target)
#Train Test Split
seed = 1234
sample_size = floor(test_train_split*nrow(sample))
set.seed(seed)
train_set = sample(seq_len(nrow(sample)), size=sample_size)
train = sample[train_set,]
test = sample[-train_set,]
#Build the model
linear_model <-vglm(as.formula(f),family = "multinomial",data=train)
#Summarize the model
#print(summary(linear_model))
#Run Predictions
x<-select(test, -target)
y<-select(test, target)
probability<-predict(linear_model,x,type="response")
test$pred_log_reg<-apply(probability,1,which.max)
test$pred_log_reg[which(test$pred_log_reg=="1")]<-levels(test[,target])[1]
test$pred_log_reg[which(test$pred_log_reg=="2")]<-levels(test[,target])[2]
#Accuracy of the model
mtab<-table(test$pred_log_reg,test[,target])
confusion = confusionMatrix(mtab)
return(list(linear_model, f, mtab, confusion))
}
run_nn_model <- function(data, target, columns, interactions=c()){
model = c(columns, interactions)
f = build_model_string(target, columns, interactions)
sample = select(data, columns, target)
#Train Test Split
seed = 1234
sample_size = floor(test_train_split*nrow(sample))
set.seed(seed)
train_set = sample(seq_len(nrow(sample)), size=sample_size)
train = sample[train_set,]
test = sample[-train_set,]
#Build the model
neural_model <-nnet(as.formula(f),data=train,size = 4,decay = 0.0001,maxit = 500)
#Summarize the model
#print(summary(neural_model))
#Run Predictions
x<-select(test, -target)
y<-select(test, target)
#Predict using the model
test$pred_nnet<-predict(neural_model,x,type='class')
#str(f)
#Accuracy of the model
mtab<-table(test$pred_nnet,test[,target])
#print(summary(mtab))
confusion = confusionMatrix(mtab)
return(list(neural_model, f, mtab, confusion))
}
#helper function for extracting col names
#TODO: add cols that are factors but also ints
factor_columns <- function(dataFrame){
return(colnames(dataFrame[,sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
non_factor_columns <- function(dataFrame){
return(colnames(dataFrame[, !sapply(dataFrame, is.factor) & colnames(dataFrame) != "id"]))
}
glucose_data =  loadData('GlucoseGeneStudy.csv')
glucose_data$Glucose = as.double(glucose_data$Glucose)
glucose_data$Gender = factor(glucose_data$Gender)
glucose_data$Race = factor(glucose_data$Race)
simple_model = lm(data=glucose_data, formula = Glucose ~ Gender+X10)
summary(simple_model)
prediction_confidence = predict(simple_model, newdata = data.frame(Gender="M",X10=17), interval = c("confidence"), type = c("response"), level =0.99)
prediction_predict = predict(simple_model, newdata = data.frame(Gender="M",X10=17), interval = c("predict"), type = c("response"), level =0.99)
experiment_data = loadData('GlucoseGeneStudy_mod.csv')
#let's remove categorical variables since we only seek to look for gene relationships
experiment_data[, 'Gender'] = c(NULL)
experiment_data[, 'Race'] = c(NULL)
f = build_model_string(target = 'Glucose', columns=colnames(experiment_data[,2:41]))
experiment_interactions = c() #assumue none for now
full_model = lm(data=experiment_data, formula=as.formula(f))
summary(full_model)
test_data = loadData('GlucoseGeneStudy_mod.csv')
simpler_model = lm(data=test_data, formula = Glucose ~ X10+log(X4)+X16+X17+X28+X29)
summary(simpler_model)
confint(simpler_model)
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data, aes(x=predictor, y=target)) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
View(test_data)
plot_prediction_and_confidence(simpler_model, test_data, 'Glucose', 'X10', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data, aes(x=predictor, y=target)) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, c(predictor)]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'Glucose', 'X10', 0.99 )
View(test_data)
test_data[, 'X10']
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data, aes(x=predictor, y=target)) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, str(predictor)]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'Glucose', 'X10', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data, aes(x=predictor, y=target)) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
sort(test_data[, 'X10'])
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(aes(x=data[,predictor], y=data[,target])) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
#input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data=data, aes(x=data[,predictor], y=data[,target])) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
#input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data=data, aes(x=data[,predictor], y=data[,target])) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data=data, aes(x=data[,predictor], y=data[,target])) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(predictor = sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(predictor = sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data=data, aes(x=data[,predictor], y=data[,target])) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
str(data.frame(predictor = sort(input)))
input = data[, predictor]
predictions_cl = predict(model, newdata = data.frame(predictor = sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(predictor = sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
plot_prediction_and_confidence = function(model, data, predictor, target, level=0.99){
plot = ggplot(data=data, aes(x=data[,predictor], y=data[,target])) +
geom_point(color='Blue', size = 2) +
geom_smooth(method = lm, se=TRUE, level=alpha, color='Red')
input = data[, predictor]
str(data.frame(predictor = sort(input)))
predictions_cl = predict(model, newdata = data.frame(predictor = sort(input)), interval = c('predict'), type=c('response'), level=level)
regress_cl = predict(model, newdata = data.frame(predictor = sort(input)), interval = c('confidence'), type=c('response'), level=level)
plot +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=upr), color='Green') +
geom_line(data=data.frame(predictions_cl), aes(x=sort(input), y=lwr), color='Green') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=upr), color='Blue') +
geom_line(data=data.frame(regress_cl), aes(x=sort(input), y=lwr), color='Blue')
}
plot_prediction_and_confidence(simpler_model, test_data, 'X10', 'Glucose', 0.99 )
